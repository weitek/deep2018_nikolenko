# Конспект книги Николенко "Глубокое обучение"

[Николенко С.И. на wikipedia](https://ru.wikipedia.org/wiki/Николенко,_Сергей_Игоревич "Николенко Сергей Игоревич")

## Часть I. Как обучать нейронные сети

### Глава 1. От биологии к информатике, *или We need to go deeper*

#### 1.1. Революция обучения глубоких сетей

> В 2005–2006 годах группы исследователей под руководством
> Джеффри Хинтона (Geoffrey Hinton) в университете Торонто и Йошуа Бенджи (Yoshua Bengio)
> в университете Монреаля научились обучать глубокие нейронные сети.

> Решение, предложенное группой Хинтона в середине 2000-х годов, пришло
> в виде предобучения без учителя, когда сеть сначала обучается на большом наборе
> данных без разметки, а потом уже дообучается на размеченных данных, используя
> это приближение. Например, если мы хотим распознавать человеческие лица, то
> давайте сначала пообучаем нейронную сеть на фотографиях с людьми вообще, без
> разметки (таких фотографий можно легко набрать сколь угодно много), а уже
> потом, когда сеть «насмотрится» на неразмеченные фотографии, дообучим ее на
> имеющемся размеченном наборе данных. Оказалось, что при этом конечный результат
> становится намного лучше, а хорошие и интересные признаки сеть начинает
> выделять еще на этапе предобучения без учителя.

#### 1.2. Искусственный интеллект и машинное обучение

> во второй половине 1950-х и начале 1960-х годов, появились и
> самообучающиеся машины, в частности перцептрон Розенблатта

> 1970-е годы стали временем расцвета систем, основанных на знаниях
> (knowledge-based systems), которые до сих пор являются важной частью науки
> об экспертных системах. Суть здесь состоит в том, чтобы накопить достаточно
> большой набор правил и знаний о предметной области, а затем делать выводы.
> Одним из самых ярких примеров таких проектов стала система MYCIN, посвященная
> идентификации бактерий, вызывающих серьезные инфекции, а затем рекомендующая
> антибиотики [65, 494]. В ней было около 600 правил, и ее результаты (она
> выдавала подходящий метод лечения в 69% случаев) были не хуже, чем у опытных
> врачей, и существенно лучше, чем у начинающих. Более того, такие системы
> могли объяснить, как именно они пришли к тому или иному решению, и оценить
> свою уверенность в этой гипотезе. Позднее они стали прообразами графических
> вероятностных моделей.

> Затем исследователи снова вспомнили о нейронных сетях: к началу 1980-х
> годов был разработан алгоритм обратного распространения ошибки (его мы
> подробно обсудим в главе 2), что открыло дорогу самым разнообразным архитектурам.
> Одним из ключевых понятий 1980-х годов был коннекционизм (connectionism):
> пришедшая из когнитивных наук идея о том, что нужно не пытаться задавать
> аксиоматические формальные системы для последующих рассуждений в них, а
> строить большие ансамбли параллельно работающих нейронов, которые, подобно
> человеческому мозгу, как-нибудь сами разберутся, что им делать. К концу
> восьмидесятых уже появилась бо􀀀льшая часть основных архитектур, о которых мы будем
> говорить в этой книге: сверточные сети, автокодировщики, рекуррентные сети...

> Поэтому вторая волна увлечения
> искусственным интеллектом закончилась в начале девяностых, когда многие
> компании не смогли оправдать завышенных ожиданий и лопнули.

> В 1990-е годы основной акцент сместился на машинное обучение и поиск
> закономерностей в данных, причем нейронные сети, как мы уже упоминали выше, не
> считались особенно перспективными. Зато самих данных, особенно с развитием
> Интернета, становилось все больше, компьютеры становились все быстрее. В
> итоге в середине 2000-х годов очередная новая идея наконец-то сработала, к ней
> быстро подтянулись другие

#### 1.3. Немного о словах: каким бывает машинное обучение

> что такое, собственно, машинное обучение (machine learning).
> Интуитивно понятно, что «обучение» — это когда некая модель каким-то образом
> «обучается», а потом начинает выдавать результаты, то есть, скорее всего, что-то
> предсказывать. Можно даже дать очень общее определение «обучаемости»,
> примерно такое, какое дает Томас Митчелл в классической книге «Машинное
> обучение» [368]: «Компьютерная программа обучается по мере накопления опыта
> относительно некоторого класса задач T и целевой функции P, если качество решения
> этих задач (относительно P) улучшается с получением нового опыта».

> Хотя это определение звучит чрезвычайно обобщенно и абстрактно, оно на
> самом деле позволяет прояснить некоторые важные моменты. Например,
> центральное место в нем занимают не данные (хотя они тоже есть), а целевая функция.
> Когда вы начинаете решать любую практическую задачу, крайне важно еще «на
> берегу» определить целевую функцию, договориться о том, как вы будете
> оценивать результаты. Выбор целевой функции полностью определяет всю дальнейшую
> работу, и даже в похожих задачах разные целевые функции могут привести к
> совершенно разным моделям. Например, было бы здорово «научить компьютер
> читать», но сначала нужно определить, что это, собственно, значит. Уметь правильно
> отвечать на вопросы по «прочитанному» тексту? Сделать синтаксический разбор
> предложения? Показать самые релевантные данному тексту статьи «Википедии»?
> Разные ответы приводят к разным моделям и направлениям исследований.

> Два основных класса задач машинного обучения — это задачи обучения
> с учителем (supervised learning) и обучения без учителя (unsupervised learning).

> При обучении с учителем на вход подается набор тренировочных примеров,
> который обычно называют обучающим или тренировочным набором данных (training
> set или training sample — тренировочная выборка), и задача состоит в том, чтобы
> продолжить уже известные ответы на новый опыт, выраженный обычно в виде
> тестового набора данных (test set, test sample). Основное предположение здесь в том,
> что данные, доступные для обучения, будут чем-то похожи на данные, на которых
> потом придется применять обученную модель, иначе никакое обобщение будет
> невозможно. Для «чтения» текста пример обучения с учителем — это обучение
> модели, которая строит деревья синтаксического разбора предложений (какие слова
> от каких зависят) по набору деревьев, построенных людьми для конкретных
> предложений. Предположение здесь в том, что деревья разбора строятся по одним и тем
> же законам, и модель, обученную на некотором наборе деревьев разбора, можно
> будет применить и к новым предложениям, не входящим в обучающий набор. Если
> это предположение нарушится, модель работать не будет. Например, если
> лингвисты размечали предложения на английском языке, а потом применили обученную
> модель к немецкому, где буквы примерно те же, но синтаксис совершенно другой,
> ожидать от модели разумного поведения не стоит.

> Задачи обучения с учителем обычно делятся на задачи классификации и
> регрессии. В задаче классификации нужно поданный на вход объект определить в один из
> (обычно конечного числа) классов, например, разделить фотографии животных на
> кошек, собак, лошадей и «все остальное»; или по фотографии человеческого лица
> понять, кто из ваших друзей в социальной сети на ней изображен. Если
> продолжать пример с языком, то типичная задача классификации — это разметка слов
> по частям речи. А в задаче регрессии нужно предсказать значение некоей
> функции, у которой обычно может быть бесконечно много разных значений. Например,
> по росту человека предсказать его вес, сделать прогноз завтрашней погоды,
> предсказать цену акции или, скажем, выделить на фотографии прямоугольник, в
> котором находится человеческое лицо — сделать это необходимо, чтобы затем эти
> прямоугольники подать на вход упомянутому выше классификатору.

> Деление на регрессию и классификацию, конечно, очень условно, можно
> легко придумать «промежуточные» примеры (тот же разбор предложения — к какому
> классу отнести задачу «построить дерево»?). Но обычно ясно, какую задачу мы
> решаем, и это деление имеет содержательный смысл: меняются целевые функции
> и, как следствие, процесс обучения. А есть и откровенно иные виды задач, не
> укладывающиеся в эту несложную классификацию. Например, в поисковых и
> рекомендательных системах часто встречается задача обучения ранжирования (learning to
> rank). Она ставится так: по имеющимся данным (в поисковой системе это будут
> тексты документов и прошлое поведение пользователей) отранжировать,
> расставить имеющиеся объекты в порядке убывания целевой функции (в поисковой
> системе она называется релевантностью: насколько данный документ подходит,
> что-бы выдать его в ответ на данный запрос). Эта задача чем-то похожа на задачу
> регрессии — нам так или иначе нужно предсказывать непрерывную целевую
> функцию, ту самую релевантность. Но при этом значений самой функции в данных
> совсем нет, да они нам и не важны. Имеют значение только результаты сравнения
> этой функции на разных объектах (какой документ будет выше другого в
> поисковой выдаче). Это приводит к ряду интересных и специфических методов обучения.

> Типичнейший пример задачи обучения без
> учителя — это кластеризация (clustering): нужно разбить данные на заранее
> неизвестные классы по некоторой мере похожести так, чтобы точки, отнесенные к
> одному и тому же кластеру, были как можно ближе друг к другу, как можно более
> похожи, а точки из разных кластеров были бы как можно дальше друг от друга, как
> можно менее похожи. Например, решив задачу кластеризации, можно выделить
> семейства генов из последовательностей нуклеотидов, или кластеризовать
> пользователей вашего веб-сайта и персонализовать его под каждый кластер, или
> сегментировать медицинский снимок, чтобы легко было понять, где же там опухоль.

> Еще одна часто встречающаяся задача обучения без учителя — это снижение
> размерности (dimensionality reduction), когда входные данные имеют большую
> размерность (например, если у вас на входе разбитый на слова текст, размерность
> будет исчисляться десятками тысяч, а если фотографии — миллионами), а задача
> состоит в том, чтобы построить представление данных меньшей размерности,
> которое тем не менее будет достаточно полно отражать исходные данные. То есть,
> например, по представлению меньшей размерности можно будет достаточно
> успешно реконструировать исходные точки большой размерности. Это можно
> рассматривать как частный случай общей задачи выделения признаков (feature extraction),
> и мы будем подробно говорить об этом на протяжении всей книги, а особенно в
> разделе 5.5, где речь пойдет об автокодировщиках.

> И наконец, третий и самый общий класс задач обучения без учителя —
> задача оценки плотности: нам даны точки данных {x1;...;xN} и, возможно, какие-то
> априорные представления о том, откуда взялись эти точки, а хочется оценить
> распределение p(x), из которого они получились. Это очень общая постановка задачи,
> к ней можно многое свести, и нейронные сети тоже отчасти ее и решают.

> Нередко в жизни возникает нечто среднее между обучением с учителем и
> обучением без учителя. Так обычно получается тогда, когда неразмеченные примеры
> найти очень легко, а размеченные получить сложно. Например, во все том же
> примере с синтаксическим разбором набрать сколько угодно неразмеченных текстов
> не представляет никакой сложности, а вот вручную нарисовать даже одно дерево
> нелегко. Или, скажем, задумайтесь о том, что такое «размеченные данные» для
> распознавания речи. Просто установить соответствие между звуковым файлом с
> речью и текстом, особенно если тексты достаточно длинные, здесь может быть
> недостаточно. По-настоящему размеченные данные для распознавания — это звуковые
> файлы, в которых вручную отмечены (или хотя бы проверены) границы каждой
> фонемы, каждого звука человеческой речи. Это адский труд, обычно делегируемый
> младшим научным сотрудникам, но даже целая армия лингвистов-фонологов
> будет двигаться достаточно медленно. А неразмеченных звуков живой человеческой
> речи вы можете записать сколько угодно, просто включив диктофон на запись.
> Такую ситуацию иногда называют обучением с частичным привлечением учителя,
> или полуконтролируемым обучением (английский термин semi-supervised learning
> устоялся куда больше), и с ней мы тоже не раз столкнемся в этой книге.

>В главе 9 мы с вами встретимся с другой постановкой задачи — обучением с
>подкреплением (reinforcement learning), когда агент, находясь в некоей среде,
> производит те или иные действия и получает за это награды. Цель агента — получить как
> можно большую награду с течением времени, а для этого неплохо бы понять, какие
> действия в конечном счете ведут к успеху. Так можно обучиться играть в разные
> игры или, например, сделать отличный протокол для A/B-тестирования.

#### 1.4. Особенности человеческого мозга

#### 1.5. Пределы нейробиологии: что мы на самом деле знаем?

#### 1.6. Блеск и нищета современных нейронных сетей

### Глава 2. Предварительные сведения, *или Курс молодого бойца*

#### 2.1. Теорема Байеса

#### 2.2. Функции ошибки и регуляризация

#### 2.3. Расстояние Кульбака — Лейблера и перекрестная энтропия

#### 2.4. Градиентный спуск: основы

#### 2.5. Граф вычислений и дифференцирование на нем

#### 2.6. И о практике: введение в TensorFlow и Keras

### Глава 3. Перцептрон, *или Эмбрион мудрого компьютера*

#### 3.1. Когда появились искусственные нейронные сети

#### 3.2. Как работает перцептрон

#### 3.3. Современные перцептроны: функции активации

#### 3.4. Как же обучаются настоящие нейроны

#### 3.5. Глубокие сети: в чем прелесть и в чем сложность?

#### 3.6. Пример: распознавание рукописных цифр на TensorFlow

## Часть II. Основные архитектуры

### Глава 4. Быстрее, глубже, сильнее, *или Об оврагах, долинах и трамплинах*

#### 4.1. Регуляризация в нейронных сетях

#### 4.2. Как инициализировать веса

#### 4.3. Нормализация по мини-батчам

#### 4.4. Метод моментов: Ньютон, Нестеров и Гессе

#### 4.5. Адаптивные варианты градиентного спуска

### Глава 5. Сверточные нейронные сети и автокодировщики, *или Не верь глазам своим*

#### 5.1. Зрительная кора головного мозга

#### 5.2. Свертки и сверточные сети

#### 5.3. Свертки для распознавания цифр

#### 5.4. Современные сверточные архитектуры

#### 5.5. Автокодировщики

#### 5.6. Пример: кодируем рукописные цифры

### Глава 6. Рекуррентные нейронные сети, *или Как правильно кусать себя за хвост*

#### 6.1. Мотивация: обработка последовательностей

#### 6.2. Распространение ошибки и архитектуры RNN

#### 6.3. LSTM

#### 6.4. GRU и другие варианты

#### 6.5. SCRN и другие: долгая память в обычных RNN

#### 6.6. Пример: порождаем текст символ за символом

## Часть III. Новые архитектуры и применения

### Глава 7. Как научить компьютер читать, *или Математик - Мужчина + Женщина =*

#### 7.1. Интеллектуальная обработка текстов

#### 7.2. Распределенные представления слов: word2vec

#### 7.3. Русскоязычный word2vec на практике

#### 7.4. GloVe: раскладываем матрицу правильно

#### 7.5. Вверх и вниз от представлений слов

#### 7.6. Рекурсивные нейронные сети и синтаксический разбор

### Глава 8. Современные архитектуры, *или Как в споре рождается истина*

#### 8.1. Модели с вниманием и encoder-decoder

#### 8.2. Порождающие модели и глубокое обучение

#### 8.3. Состязательные сети

#### 8.4. Практический пример и трюк с логистическим сигмоидом

#### 8.5. Архитектуры, основанные на GAN

### Глава 9. Глубокое обучение с подкреплением, *или Удивительное происшествие с чемпионом*

#### 9.1. Обучение с подкреплением

#### 9.2. Марковские процессы принятия решений

#### 9.3. От TDGammon к DQN

#### 9.4. Бамбуковая хлопушка

#### 9.5. Градиент по стратегиям и другие применения

### Глава 10. Нейробайесовские методы, *или Прошлое и будущее машинного обучения*

#### 10.1. Теорема Байеса и нейронные сети

#### 10.2. Алгоритм EM

#### 10.3. Вариационные приближения

#### 10.4. Вариационный автокодировщик

#### 10.5. Байесовские нейронные сети и дропаут

#### 10.6. Заключение: что не вошло в книгу и что будет дальше
